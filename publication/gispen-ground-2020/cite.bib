@article{gispen_ground_2020,
 abstract = {We introduce reinforcement learning (RL) formulations of the problem of finding the ground state of a many-body quantum mechanical model defined on a lattice. We show that stoquastic Hamiltonians -- those without a sign problem -- have a natural decomposition into stochastic dynamics and a potential representing a reward function. The mapping to RL is developed for both continuous and discrete time, based on a generalized Feynman--Kac formula in the former case and a stochastic representation of the Schr\"odinger equation in the latter. We discuss the application of this mapping to the neural representation of quantum states, spelling out the advantages over approaches based on direct representation of the wavefunction of the system.},
 annote = {Comment: Under review for MSML2021},
 author = {Gispen, Willem and Lamacraft, Austen},
 file = {arXiv Fulltext PDF:/home/willem/Zotero/storage/BCRL5QLH/Gispen and Lamacraft - 2020 - Ground States of Quantum Many Body Lattice Models .pdf:application/pdf;arXiv.org Snapshot:/home/willem/Zotero/storage/APDF46V5/2012.html:text/html},
 journal = {arXiv:2012.07063 [cond-mat, physics:quant-ph]},
 keywords = {Condensed Matter - Disordered Systems and Neural Networks, Quantum Physics},
 month = {December},
 note = {arXiv: 2012.07063},
 title = {Ground States of Quantum Many Body Lattice Models via Reinforcement Learning},
 url = {http://arxiv.org/abs/2012.07063},
 urldate = {2020-12-24},
 year = {2020}
}

